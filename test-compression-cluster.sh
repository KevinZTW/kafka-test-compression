#!/bin/bash

COMPRESSION_TYPE=(gzip lz4 zstd snappy)

GZIP_BUFFER_SIZES=(512 2048 8192 32768)
LZ4_BLOCK_SIZES=(4 5 6 7)
ZSTD_WINDOW_SIZES=(0 10 16 22)
SNAPPY_BLOCK_SIZES=(1024 4096 16384 65536)


leader=192.168.1.109

followers=(macbook1)
followers=(homelab macbook1)
# ===============================[global variables]===============================
declare -r KAFKA_DIR=${KAFKA_DIR:-$WORK_DIR/kafka}
WORK_DIR=~/kafka-experiment
KAFKA_HEAP_OPTS='-Xms12G -Xmx12G'


function genCompressionParamString() {
    compression_type=$1
    buffer_size=$2

    output="compression.type=$compression_type"

    if [[ "$compression_type" == "zstd" ]]; then
        output+=" compression.zstd.window=$buffer_size"
    elif [[ "$compression_type" == "lz4" ]]; then
        output+=" compression.lz4.block=$buffer_size"
    elif [[ "$compression_type" == "snappy" ]]; then
        output+=" compression.snappy.block=$buffer_size"
    elif [[ "$compression_type" == "gzip" ]]; then
        output+=" compression.gzip.buffer=$buffer_size"
    fi

    printf "%s\n" "$output"
}


function install_follower_dependencies(){
    host=$1
    echo "install dependencies for host $host"
    ssh $host 'bash -s' < install.sh
}

function setup_cluster(){
    # cleanup the containers generated by previous test
    cleanup

    compression_type=$1
    buffer_size=$2

    echo "compression type: $compression_type"
    echo "buffer size: $buffer_size"


    echo "start the controller in leader"
    CONTROLLER_OUTPUT=$($WORK_DIR/astraea/docker/start_controller.sh)
    echo "$CONTROLLER_OUTPUT"

    temp=$(echo "$CONTROLLER_OUTPUT" | grep -o 'controller.quorum.voters=[0-9]*@[^ ]*')
    CONTROLLER_ADDRESS=$(echo "$temp" | awk -F'=' '{print $2}')
    CLUSTER_ID=$(echo "$CONTROLLER_OUTPUT" | grep -oE 'run CLUSTER_ID=[^ ]+' | cut -d '=' -f 2)

    echo $CONTROLLER_ADDRESS
    echo $CLUSTER_ID

    echo "start the broker"
    compression_param_str=$(genCompressionParamString $compression_type $buffer_size)
    echo "------------------------"
    echo "HEAP_OPTS=$KAFKA_HEAP_OPTS CLUSTER_ID=$CLUSTER_ID BROKER_PORT=9092 ACCOUNT=kevinztw REVISION=kip-780 KAFKA_ACCOUNT=kevinztw $WORK_DIR/astraea/docker/start_broker.sh log.cleaner.threads=2 controller.quorum.voters=$CONTROLLER_ADDRESS $compression_param_str"
    echo "------------------------"
    broker_output=$(HEAP_OPTS=$KAFKA_HEAP_OPTS CLUSTER_ID=$CLUSTER_ID BROKER_PORT=9092 ACCOUNT=kevinztw REVISION=kip-780 KAFKA_ACCOUNT=kevinztw $WORK_DIR/astraea/docker/start_broker.sh log.cleaner.threads=2 controller.quorum.voters=$CONTROLLER_ADDRESS $compression_param_str)
    echo "$broker_output"


    LEADER_ADDRESS=$(echo "$broker_output" | awk '/broker address:/ {print $3}')
    
    
    for host in "${followers[@]}"
    do
        echo "------------------------"
        echo "start the broker in $host"
        docker image pull ghcr.io/kevinztw/astraea/broker:kip-780

        # TODO: would be better to make working dir as a parameter
        # str="BUFFER_SIZE=$buffer_size COMPRESSION_TYPE=$compression_type CLUSTER_ID=$CLUSTER_ID BROKER_PORT=9092 ACCOUNT=kevinztw REVISION=kip-780 KAFKA_ACCOUNT=kevinztw ~/kafka-experiment/astraea/docker/start_broker.sh controller.quorum.voters=$CONTROLLER_ADDRESS"
        str="HEAP_OPTS='$KAFKA_HEAP_OPTS' CLUSTER_ID=$CLUSTER_ID BROKER_PORT=9092 ACCOUNT=kevinztw REVISION=kip-780 KAFKA_ACCOUNT=kevinztw ~/kafka-experiment/astraea/docker/start_broker.sh log.cleaner.threads=2 controller.quorum.voters=$CONTROLLER_ADDRESS $compression_param_str"
        ssh $host 'export PATH=$PATH:/usr/local/bin; bash -s' <<< $str
    done
    sleep 5
    # now the cluster is ready, should be fine to test
}

function cleanup(){
    echo "clean up"
    CONTROLLER_ID=$(docker ps -a | grep "ghcr.io/skiptests/astraea/controller" | awk '{print $1}')
    echo $CONTROLLER_ID |  xargs docker stop
    echo $CONTROLLER_ID |  xargs docker rm

    BROKER_ID=$(docker ps -a | grep "ghcr.io/kevinztw/astraea/broker" | awk '{print $1}')
    echo $BROKER_ID |  xargs docker stop
    echo $BROKER_ID |  xargs docker rm

    for host in "${followers[@]}"
    do
        echo "------------------------"
        echo "clean up $host"
        ssh $host 'export PATH=$PATH:/usr/local/bin; docker ps -a | grep "ghcr.io/kevinztw/astraea/broker" | awk "{print \$1}" | xargs docker stop'
        ssh $host 'export PATH=$PATH:/usr/local/bin; docker ps -a | grep "ghcr.io/kevinztw/astraea/broker" | awk "{print \$1}" | xargs docker rm'
    done
}

function exec(){


    for compression_type in "${COMPRESSION_TYPE[@]}"
    do

        buffer_sizes=()
        if [ "$compression_type" == "gzip" ]; then
            buffer_sizes=("${GZIP_BUFFER_SIZES[@]}")
        elif [ "$compression_type" == "lz4" ]; then
            buffer_sizes=("${LZ4_BLOCK_SIZES[@]}")
        elif [ "$compression_type" == "zstd" ]; then
            buffer_sizes=("${ZSTD_WINDOW_SIZES[@]}")
        elif [ "$compression_type" == "snappy" ]; then
            buffer_sizes=("${SNAPPY_BLOCK_SIZES[@]}")
        fi
        
        for buffer_size in "${buffer_sizes[@]}" 
        do
            for host in "${followers[@]}"
            do
                echo "install dependencies for $host"
                install_follower_dependencies $host
            done
            echo "=============================="
            echo "=============================="
            echo "[test on] [$compression_type] [$buffer_size]"
            setup_cluster $compression_type $buffer_size
            sleep 10 # TODO: wait for the cluster to be ready
            
            echo "create topic"
            echo $LEADER_ADDRESS
            ./kafka/bin/kafka-topics.sh --create --topic test-compression --partitions 1 --replication-factor 2 --bootstrap-server $LEADER_ADDRESS
            echo "KAFKA_HEAP_OPTS="-Xms12G -Xmx12G" $KAFKA_DIR/bin/kafka-run-class.sh org.apache.kafka.tools.TestCompression \
                --bootstrap-server $LEADER_ADDRESS \
                --compression-type none \
                --topic test-compression \
                --data-dir $WORK_DIR/data/mock"

            output=$(KAFKA_HEAP_OPTS="-Xms12G -Xmx12G" $KAFKA_DIR/bin/kafka-run-class.sh org.apache.kafka.tools.TestCompression \
                --bootstrap-server $LEADER_ADDRESS \
                --compression-type none \
                --topic test-compression \
                --data-dir $WORK_DIR/data/mock
                )
            echo "[$compression_type]  [$buffer_size]" >> "test_compression.log"
            echo "$output" >> "test_compression.log"
        done
    done


# ===============================[test]===============================

    
    # for compression_type in "${COMPRESSION_TYPE[@]}"
    # do
    #     echo "handle type $compression_type"
    #     echo "setup the cluster"
    #     setup_cluster $compression_type 1028
        buffer_sizes=()
        if [ "$compression_type" == "gzip" ]; then
            buffer_sizes=("${GZIP_BUFFER_SIZES[@]}")
        elif [ "$compression_type" == "lz4" ]; then
            buffer_sizes=("${LZ4_BLOCK_SIZES[@]}")
        elif [ "$compression_type" == "zstd" ]; then
            buffer_sizes=("${ZSTD_WINDOW_SIZES[@]}")
        elif [ "$compression_type" == "snappy" ]; then
            buffer_sizes=("${SNAPPY_BLOCK_SIZES[@]}")
        fi

    #     for buffer_size in "${buffer_sizes[@]}"
    #     do
            # output=$(KAFKA_HEAP_OPTS="-Xms12G -Xmx12G" $KAFKA_DIR/bin/kafka-run-class.sh org.apache.kafka.tools.TestCompression \
            #     --bootstrap-server $BROKER_0_ADDRESS \
            #     --compression-type $compression_type \
            #     --topic test-compression \
            #     --buffer-size $buffer_size)
                
            # echo "$output" >> "test_compression.log"
    #     done
        
    #     echo "clean up"
    # done
}

exec